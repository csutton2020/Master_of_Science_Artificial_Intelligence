{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Christian Sutton   \n",
    "10/10/20    \n",
    "Module 6  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "SRdata = pd.read_csv(\"C:/Users/physi/Desktop/AppliedMachineLearning_EN.705.601/Mod3/master.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "**[20 pts] What is the dependent variable you decided? Why?**   \n",
    "The dependent variable selected for this case was suicides/100k pop because it represents the number of suicides corrected by a counrty's population size awhich allows countries to be compared. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2  \n",
    "**[20 pts] Set the dependent variable into two categories based on a defensible criteria. (Hint: skirts of the probability density function)**  \n",
    "\n",
    "I have taken \"suicides/100k pop\" and binned it into two groups to build a dependent variable. One group is 17.73 per 100K and less and the other group is greater than 17.73 per 100K, where 17.73 represents the the top quartile of suicides per 100k. The top quartile seems like a reasonable threshold for distingishing a high rate of suicide. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3  \n",
    "**[20 pts] Develop your classification model(s) to solve your defined problem.**   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I am removing countries that have been contributing repeated zeros to the data set\n",
    "\n",
    "SRdata = SRdata[SRdata.country != \"Antigua and Barbuda\"]\n",
    "SRdata = SRdata[SRdata.country != \"Aruba\"]\n",
    "SRdata = SRdata[SRdata.country != \"Bosnia and Herzegovina\"]\n",
    "SRdata = SRdata[SRdata.country != \"Cabo Verdea\"]\n",
    "SRdata = SRdata[SRdata.country != \"Cyprus\"]\n",
    "SRdata = SRdata[SRdata.country != \"Dominica\"]\n",
    "SRdata = SRdata[SRdata.country != \"Grenada\"]\n",
    "SRdata = SRdata[SRdata.country != \"Jamaica\"]\n",
    "SRdata = SRdata[SRdata.country != \"Kuwait\"]\n",
    "SRdata = SRdata[SRdata.country != \"Maldives\"]\n",
    "SRdata = SRdata[SRdata.country != \"Montenegro\"]\n",
    "SRdata = SRdata[SRdata.country != \"Oman\"]\n",
    "SRdata = SRdata[SRdata.country != \"Qatar\"]\n",
    "SRdata = SRdata[SRdata.country != \"Saint Kitts and Nevis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since HDI for year -  is missing most of it's values, this feature will be removed\n",
    "#Country-year -  is redundant to features \"year\" and \"country\"\n",
    "#gdp_for_year - removing this feature because it isn't used later\n",
    "#removing counntry, year and gdp_per_capita, due to low correlation\n",
    "#population and suicides_no are being removed due to unwanted correlation between features\n",
    "\n",
    "SRdata =SRdata.drop([\"HDI for year\",\"country-year\",\" gdp_for_year ($) \",\"country\",\"year\",\\\n",
    "                     \"gdp_per_capita ($)\",\"population\",\"suicides_no\"], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binning my dependent variable\n",
    "\n",
    "cut_labels = ['Low chance', 'High Chance']\n",
    "cut_bins = [-.1, 17.73, 2000]\n",
    "SRdata['Chance of suicide'] = pd.cut(SRdata['suicides/100k pop'], bins=cut_bins, labels=cut_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode ordinal values to age, suicide chance, \n",
    "ages = {'15-24 years':20, '5-14 years':10,'25-34 years':30,'35-54 years':45,'55-74 years':65,'75+ years':75}\n",
    "Generations = {'G.I. Generation':1,'Silent':2,'Boomers':3,\\\n",
    "               'Generation X':4,'Millenials':5,'Generation Z':6}\n",
    "Chance= {'High Chance':1,'Low chance':0}\n",
    "SRdata['age']= SRdata['age'].map(ages)\n",
    "SRdata['generation']= SRdata['generation'].map(Generations)\n",
    "SRdata['Chance of suicide']= SRdata['Chance of suicide'].map(Chance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OneHotEncode sex\n",
    "SRdata =pd.get_dummies(SRdata)\n",
    "SRdata =SRdata.drop([\"sex_female\",\"suicides/100k pop\"],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>generation</th>\n",
       "      <th>Chance of suicide</th>\n",
       "      <th>sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  generation  Chance of suicide  sex_male\n",
       "0   20           4                  0         1\n",
       "1   45           2                  0         1\n",
       "2   20           4                  0         0\n",
       "3   75           1                  0         1\n",
       "4   30           3                  0         1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " SRdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4  \n",
    "**[20 pts] Evaluate (and report) the model performance(s) using some of the standard techniques (e.g. 80-20 split, 10-fold cross validation, etc.).**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spilt independent and dependent variables \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# 80/20 split\n",
    "X, Y =SRdata.iloc[:,[0,1,3]], SRdata.iloc[:,2]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=.2,random_state=0)\n",
    "\n",
    "pipe_l1 = make_pipeline(StandardScaler(),\n",
    "                            RandomForestClassifier(5,random_state=10))\n",
    "pipe_l1.fit(X_train, y_train)\n",
    "y_pred = pipe_l1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape\n",
    "y_pred =y_pred.reshape((5162,1))\n",
    "y_test = np.array(y_test)\n",
    "y_test= y_test.reshape((5162,1))\n",
    "\n",
    "# make new dataframe\n",
    "Results = pd.DataFrame(data=y_pred, columns= [\"Predicted\"])\n",
    "Results[\"Actual\"]= y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted  Actual\n",
       "0          0       0\n",
       "1          0       0\n",
       "2          0       0\n",
       "3          1       1\n",
       "4          1       1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score =0.66  Accuracy =0.82 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "print(f'F1 Score ={f1_score(Results.iloc[:,1],Results.iloc[:,0]):.2f}  \\\n",
    "Accuracy ={accuracy_score(Results.iloc[:,1],Results.iloc[:,0]):.2f} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5  \n",
    "**[20 pts] Using your classifier model, what is the predicted category of your dependent variable for the input: \"year=2000, generation=Generation X, age=20, gender=male\"?**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer1 = pipe_l1.predict(np.array([20,4,1]).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The answer of [0] means the datapoint represents a low risk of suicide in this model\n"
     ]
    }
   ],
   "source": [
    "print(f' The answer of {answer1} means the datapoint represents a low risk of suicide in this model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# problem 6  \n",
    "**[20 pts bonus] Using your (perhaps a different?) model, what is the actual probability of a\n",
    "\"Generation X 20-year-old male living in a country with 40000 gdp_per_capita\" would commit suicide?**  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer2 = pipe_l1.predict_proba(np.array([20,4,1]).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The answer of [[0.68720502 0.31279498]] means the datapoint represents a probability of 68% class 0 (low risk)\n",
      " and 31% probability of class 1 (highrisk of suicide) in this model\n"
     ]
    }
   ],
   "source": [
    "print(f' The answer of {answer2} means the datapoint represents a probability of 68% class 0 (low risk)')\n",
    "print(f' and 31% probability of class 1 (high risk of suicide) in this model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
