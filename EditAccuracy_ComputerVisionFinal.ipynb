{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "WTSV_JlgFmuH",
        "d8THOFUtFYd7",
        "nasq3SErFMU_"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Computer Vision Final - Spring 2023\n",
        "#### FER-2013 dataset with Convolutional Block Attention Module\n"
      ],
      "metadata": {
        "id": "BqfUUXjfFqSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "from google.colab import drive\n",
        "import torch\n",
        "from torchvision import transforms, datasets\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import optim\n",
        "from torch import nn as nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.transforms import ToTensor, Normalize, transforms\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Myg5IDlULVaT",
        "outputId": "42f149f6-3fcd-4e05-f32a-01727d30abb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/ComputerVision/Emotion.zip\", 'r')\n",
        "zip_ref.extractall(\"/content/FER2013\")\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "fZIo2Upch_1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls FER2013/train\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hnu-Yju_iUNm",
        "outputId": "571dd18e-eadd-4052-e6ed-251f7b5fe181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "angry  disgust\tfear  happy  neutral  sad  surprise\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/Jongchan/attention-module.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rea2XyTWkB9C",
        "outputId": "b5c15f52-a1da-44d5-9fe4-2d74a1aa620f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'attention-module' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_transform = transforms.Compose([transforms.ToTensor(), transforms.Grayscale(),  transforms.Resize(256,antialias=True) ])\n",
        "\n",
        "fer_2013 = datasets.ImageFolder(root='FER2013/train/',\n",
        "                                           transform=data_transform)\n",
        "train_load, dev_load = torch.utils.data.random_split(fer_2013, [25838, 2871])"
      ],
      "metadata": {
        "id": "ON_N0ZuEznRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_load,\n",
        "                                             batch_size=128, shuffle=True,\n",
        "                                             num_workers=2)\n",
        "val_loader = torch.utils.data.DataLoader(dev_load,\n",
        "                                             batch_size=128, shuffle=True,\n",
        "                                             num_workers=2)\n",
        "fer_2013_test = datasets.ImageFolder(root='FER2013/test/',\n",
        "                                           transform=data_transform)\n",
        "test_loader = torch.utils.data.DataLoader(fer_2013_test,\n",
        "                                             batch_size=128, shuffle=True,\n",
        "                                             num_workers=2)"
      ],
      "metadata": {
        "id": "U9xqLA8dzoVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/attention-module/train_imagenet.py --ngpu 1 --arch resnet --depth 34 --epochs 30 --batch-size 256 --lr 0.1 --att-type CBAM --prefix RESNET50_IMAGENET_CBAM"
      ],
      "metadata": {
        "id": "tEAwMT9T3PWg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8038ff2d-12de-4349-9102-e2934f77faa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  File \"/content/attention-module/train_imagenet.py\", line 181\n",
            "    target = target.cuda(async=True)\n",
            "                         ^^^^^\n",
            "SyntaxError: invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### BAM Module"
      ],
      "metadata": {
        "id": "WTSV_JlgFmuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.size(0), -1)\n",
        "class ChannelGate(nn.Module):\n",
        "    def __init__(self, gate_channel, reduction_ratio=16, num_layers=1):\n",
        "        super(ChannelGate, self).__init__()\n",
        "        self.gate_activation = gate_activation\n",
        "        self.gate_c = nn.Sequential()\n",
        "        self.gate_c.add_module( 'flatten', Flatten() )\n",
        "        gate_channels = [gate_channel]\n",
        "        gate_channels += [gate_channel // reduction_ratio] * num_layers\n",
        "        gate_channels += [gate_channel]\n",
        "        for i in range( len(gate_channels) - 2 ):\n",
        "            self.gate_c.add_module( 'gate_c_fc_%d'%i, nn.Linear(gate_channels[i], gate_channels[i+1]) )\n",
        "            self.gate_c.add_module( 'gate_c_bn_%d'%(i+1), nn.BatchNorm1d(gate_channels[i+1]) )\n",
        "            self.gate_c.add_module( 'gate_c_relu_%d'%(i+1), nn.ReLU() )\n",
        "        self.gate_c.add_module( 'gate_c_fc_final', nn.Linear(gate_channels[-2], gate_channels[-1]) )\n",
        "    def forward(self, in_tensor):\n",
        "        avg_pool = F.avg_pool2d( in_tensor, in_tensor.size(2), stride=in_tensor.size(2) )\n",
        "        return self.gate_c( avg_pool ).unsqueeze(2).unsqueeze(3).expand_as(in_tensor)\n",
        "\n",
        "class SpatialGate(nn.Module):\n",
        "    def __init__(self, gate_channel, reduction_ratio=16, dilation_conv_num=2, dilation_val=4):\n",
        "        super(SpatialGate, self).__init__()\n",
        "        self.gate_s = nn.Sequential()\n",
        "        self.gate_s.add_module( 'gate_s_conv_reduce0', nn.Conv2d(gate_channel, gate_channel//reduction_ratio, kernel_size=1))\n",
        "        self.gate_s.add_module( 'gate_s_bn_reduce0',\tnn.BatchNorm2d(gate_channel//reduction_ratio) )\n",
        "        self.gate_s.add_module( 'gate_s_relu_reduce0',nn.ReLU() )\n",
        "        for i in range( dilation_conv_num ):\n",
        "            self.gate_s.add_module( 'gate_s_conv_di_%d'%i, nn.Conv2d(gate_channel//reduction_ratio, gate_channel//reduction_ratio, kernel_size=3, \\\n",
        "\t\t\t\t\t\tpadding=dilation_val, dilation=dilation_val) )\n",
        "            self.gate_s.add_module( 'gate_s_bn_di_%d'%i, nn.BatchNorm2d(gate_channel//reduction_ratio) )\n",
        "            self.gate_s.add_module( 'gate_s_relu_di_%d'%i, nn.ReLU() )\n",
        "        self.gate_s.add_module( 'gate_s_conv_final', nn.Conv2d(gate_channel//reduction_ratio, 1, kernel_size=1) )\n",
        "    def forward(self, in_tensor):\n",
        "        return self.gate_s( in_tensor ).expand_as(in_tensor)\n",
        "class BAM(nn.Module):\n",
        "    def __init__(self, gate_channel):\n",
        "        super(BAM, self).__init__()\n",
        "        self.channel_att = ChannelGate(gate_channel)\n",
        "        self.spatial_att = SpatialGate(gate_channel)\n",
        "    def forward(self,in_tensor):\n",
        "        att = 1 + F.sigmoid( self.channel_att(in_tensor) * self.spatial_att(in_tensor) )\n",
        "        return att * in_tensor"
      ],
      "metadata": {
        "id": "M_lQ7EZFFjTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CBAM module"
      ],
      "metadata": {
        "id": "d8THOFUtFYd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BasicConv(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1, groups=1, relu=True, bn=True, bias=False):\n",
        "        super(BasicConv, self).__init__()\n",
        "        self.out_channels = out_planes\n",
        "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n",
        "        self.bn = nn.BatchNorm2d(out_planes,eps=1e-5, momentum=0.01, affine=True) if bn else None\n",
        "        self.relu = nn.ReLU() if relu else None\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        if self.bn is not None:\n",
        "            x = self.bn(x)\n",
        "        if self.relu is not None:\n",
        "            x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.size(0), -1)\n",
        "\n",
        "class ChannelGate(nn.Module):\n",
        "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max']):\n",
        "        super(ChannelGate, self).__init__()\n",
        "        self.gate_channels = gate_channels\n",
        "        self.mlp = nn.Sequential(\n",
        "            Flatten(),\n",
        "            nn.Linear(gate_channels, gate_channels // reduction_ratio),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(gate_channels // reduction_ratio, gate_channels)\n",
        "            )\n",
        "        self.pool_types = pool_types\n",
        "    def forward(self, x):\n",
        "        channel_att_sum = None\n",
        "        for pool_type in self.pool_types:\n",
        "            if pool_type=='avg':\n",
        "                avg_pool = F.avg_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
        "                channel_att_raw = self.mlp( avg_pool )\n",
        "            elif pool_type=='max':\n",
        "                max_pool = F.max_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
        "                channel_att_raw = self.mlp( max_pool )\n",
        "            elif pool_type=='lp':\n",
        "                lp_pool = F.lp_pool2d( x, 2, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
        "                channel_att_raw = self.mlp( lp_pool )\n",
        "            elif pool_type=='lse':\n",
        "                # LSE pool only\n",
        "                lse_pool = logsumexp_2d(x)\n",
        "                channel_att_raw = self.mlp( lse_pool )\n",
        "\n",
        "            if channel_att_sum is None:\n",
        "                channel_att_sum = channel_att_raw\n",
        "            else:\n",
        "                channel_att_sum = channel_att_sum + channel_att_raw\n",
        "\n",
        "        scale = F.sigmoid( channel_att_sum ).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
        "        return x * scale\n",
        "\n",
        "def logsumexp_2d(tensor):\n",
        "    tensor_flatten = tensor.view(tensor.size(0), tensor.size(1), -1)\n",
        "    s, _ = torch.max(tensor_flatten, dim=2, keepdim=True)\n",
        "    outputs = s + (tensor_flatten - s).exp().sum(dim=2, keepdim=True).log()\n",
        "    return outputs\n",
        "\n",
        "class ChannelPool(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return torch.cat( (torch.max(x,1)[0].unsqueeze(1), torch.mean(x,1).unsqueeze(1)), dim=1 )\n",
        "\n",
        "class SpatialGate(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SpatialGate, self).__init__()\n",
        "        kernel_size = 7\n",
        "        self.compress = ChannelPool()\n",
        "        self.spatial = BasicConv(2, 1, kernel_size, stride=1, padding=(kernel_size-1) // 2, relu=False)\n",
        "    def forward(self, x):\n",
        "        x_compress = self.compress(x)\n",
        "        x_out = self.spatial(x_compress)\n",
        "        scale = F.sigmoid(x_out) # broadcasting\n",
        "        return x * scale\n",
        "\n",
        "class CBAM(nn.Module):\n",
        "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max'], no_spatial=False):\n",
        "        super(CBAM, self).__init__()\n",
        "        self.ChannelGate = ChannelGate(gate_channels, reduction_ratio, pool_types)\n",
        "        self.no_spatial=no_spatial\n",
        "        if not no_spatial:\n",
        "            self.SpatialGate = SpatialGate()\n",
        "    def forward(self, x):\n",
        "        x_out = self.ChannelGate(x)\n",
        "        if not self.no_spatial:\n",
        "            x_out = self.SpatialGate(x_out)\n",
        "        return x_out"
      ],
      "metadata": {
        "id": "HJGMKsYwExG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ResNet Module"
      ],
      "metadata": {
        "id": "nasq3SErFMU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from torch.nn import init\n",
        "# from .cbam import *\n",
        "# from .bam import *\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"3x3 convolution with padding\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, use_cbam=False):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "        if use_cbam:\n",
        "            self.cbam = CBAM( planes, 16 )\n",
        "        else:\n",
        "            self.cbam = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        if not self.cbam is None:\n",
        "            out = self.cbam(out)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, use_cbam=False):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "        if use_cbam:\n",
        "            self.cbam = CBAM( planes * 4, 16 )\n",
        "        else:\n",
        "            self.cbam = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        if not self.cbam is None:\n",
        "            out = self.cbam(out)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers,  network_type, num_classes, att_type=None):\n",
        "        self.inplanes = 64\n",
        "        super(ResNet, self).__init__()\n",
        "        self.network_type = network_type\n",
        "        # different model config between ImageNet and CIFAR\n",
        "        if network_type == \"ImageNet\":\n",
        "            self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "            self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "            self.avgpool = nn.AvgPool2d(7)\n",
        "        else:\n",
        "            self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        if att_type=='BAM':\n",
        "            self.bam1 = BAM(64*block.expansion)\n",
        "            self.bam2 = BAM(128*block.expansion)\n",
        "            self.bam3 = BAM(256*block.expansion)\n",
        "        else:\n",
        "            self.bam1, self.bam2, self.bam3 = None, None, None\n",
        "\n",
        "        self.layer1 = self._make_layer(block, 64,  layers[0], att_type=att_type)\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, att_type=att_type)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, att_type=att_type)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, att_type=att_type)\n",
        "\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        init.kaiming_normal(self.fc.weight)\n",
        "        for key in self.state_dict():\n",
        "            if key.split('.')[-1]==\"weight\":\n",
        "                if \"conv\" in key:\n",
        "                    init.kaiming_normal(self.state_dict()[key], mode='fan_out')\n",
        "                if \"bn\" in key:\n",
        "                    if \"SpatialGate\" in key:\n",
        "                        self.state_dict()[key][...] = 0\n",
        "                    else:\n",
        "                        self.state_dict()[key][...] = 1\n",
        "            elif key.split(\".\")[-1]=='bias':\n",
        "                self.state_dict()[key][...] = 0\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, att_type=None):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, use_cbam=att_type=='CBAM'))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, use_cbam=att_type=='CBAM'))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        if self.network_type == \"ImageNet\":\n",
        "            x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        if not self.bam1 is None:\n",
        "            x = self.bam1(x)\n",
        "\n",
        "        x = self.layer2(x)\n",
        "        if not self.bam2 is None:\n",
        "            x = self.bam2(x)\n",
        "\n",
        "        x = self.layer3(x)\n",
        "        if not self.bam3 is None:\n",
        "            x = self.bam3(x)\n",
        "\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        if self.network_type == \"ImageNet\":\n",
        "            x = self.avgpool(x)\n",
        "        else:\n",
        "            x = F.avg_pool2d(x, 4)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "def ResidualNet(network_type, depth, num_classes, att_type):\n",
        "\n",
        "    assert network_type in [\"ImageNet\", \"CIFAR10\", \"CIFAR100\"], \"network type should be ImageNet or CIFAR10 / CIFAR100\"\n",
        "    assert depth in [18, 34, 50, 101], 'network depth should be 18, 34, 50 or 101'\n",
        "\n",
        "    if depth == 18:\n",
        "        model = ResNet(BasicBlock, [2, 2, 2, 2], network_type, num_classes, att_type)\n",
        "\n",
        "    elif depth == 34:\n",
        "        model = ResNet(BasicBlock, [3, 4, 6, 3], network_type, num_classes, att_type)\n",
        "\n",
        "    elif depth == 50:\n",
        "        model = ResNet(Bottleneck, [3, 4, 6, 3], network_type, num_classes, att_type)\n",
        "\n",
        "    elif depth == 101:\n",
        "        model = ResNet(Bottleneck, [3, 4, 23, 3], network_type, num_classes, att_type)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "5qCw0sLqEy7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Python Module"
      ],
      "metadata": {
        "id": "H4Yv5d7GF6LA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "# from MODELS.model_resnet import *\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "argsprefix = \"testRun1\"\n",
        "argsdepth = 34\n",
        "argsatt_type = 'CBAM'\n",
        "argsarch = 'resnet'\n",
        "argslr = .1\n",
        "argsmomentum = 1e-4\n",
        "argsweight_decay = 1e-4\n",
        "argsngpu = 1\n",
        "argsresume = ''\n",
        "argsstart_epoch = 0\n",
        "argsevaluate = False\n",
        "argsepochs = 50\n",
        "network_type = \"CFAR10\"\n",
        "argsprint_freq = 10\n",
        "acc=[]\n",
        "l=[]\n",
        "def train(train_loader, model, criterion, optimizer, epoch):\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "       # Move tensors to the configured device\n",
        "        # print(\"images\" ,images.size())\n",
        "        # print(\"labels\" ,labels.size())\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    l.append(loss.item())\n",
        "    print ('Epoch {}, Loss: {:.4f}'\n",
        "                   .format(epoch+1, loss.item()))\n",
        "    # Validation\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            del images, labels, outputs\n",
        "        acc.append(correct / total)\n",
        "        print('Accuracy of the network on the {} validation images: {} %'.format(5000, 100 * correct / total))\n",
        "\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
        "    lr = argslr * (0.1 ** (epoch // 30))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if not os.path.exists('./checkpoints'):\n",
        "    os.mkdir('./checkpoints')\n",
        "\n",
        "# def main():---------------------------------------------------------------------------------------------\n",
        "global args, best_prec1\n",
        "global viz, train_lot, test_lot\n",
        "# args = parser.parse_args()\n",
        "# print (\"args\", args)\n",
        "best_prec1 = 0\n",
        "\n",
        "torch.manual_seed(1234)\n",
        "# torch.cuda.manual_seed_all(args.seed)\n",
        "# random.seed(args.seed)\n",
        "\n",
        "# create model\n",
        "if argsarch == \"resnet\":\n",
        "    model = ResidualNet( 'ImageNet', argsdepth, 7, argsatt_type )\n",
        "\n",
        "# define loss function (criterion) and optimizer\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), argslr,\n",
        "                        momentum=argsmomentum,\n",
        "                        weight_decay=argsweight_decay)\n",
        "model = torch.nn.DataParallel(model, device_ids=list(range(argsngpu)))\n",
        "#model = torch.nn.DataParallel(model).cuda()\n",
        "model = model.cuda()\n",
        "# print (\"model\")\n",
        "# print (model)\n",
        "\n",
        "# get the number of model parameters\n",
        "print('Number of model parameters: {}'.format(\n",
        "    sum([p.data.nelement() for p in model.parameters()])))\n",
        "\n",
        "# optionally resume from a checkpoint\n",
        "if argsresume:\n",
        "    if os.path.isfile(argsresume):\n",
        "        print(\"=> loading checkpoint '{}'\".format(argsresume))\n",
        "        checkpoint = torch.load(argsresume)\n",
        "        argsstart_epoch = checkpoint['epoch']\n",
        "        best_prec1 = checkpoint['best_prec1']\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "        if 'optimizer' in checkpoint:\n",
        "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
        "              .format(argsresume, checkpoint['epoch']))\n",
        "    else:\n",
        "        print(\"=> no checkpoint found at '{}'\".format(argsresume))\n",
        "\n",
        "\n",
        "cudnn.benchmark = True\n",
        "\n",
        "\n",
        "\n",
        "train_sampler = None\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(argsstart_epoch, argsepochs):\n",
        "    adjust_learning_rate(optimizer, epoch)\n",
        "\n",
        "    # train for one epoch\n",
        "    train(train_loader, model, criterion, optimizer, epoch)\n",
        "\n",
        "\n",
        "print(acc)\n",
        "print(l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6CbxWezEEBg",
        "outputId": "ed9ac2a7-ffbd-429b-9efb-e6c8f0b51357"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-a70bea7b7fbb>:129: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
            "  init.kaiming_normal(self.fc.weight)\n",
            "<ipython-input-10-a70bea7b7fbb>:133: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
            "  init.kaiming_normal(self.state_dict()[key], mode='fan_out')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of model parameters: 21444787\n",
            "Epoch 1, Loss: 1.8174\n",
            "Accuracy of the network on the 5000 validation images: 29.39742250087078 %\n",
            "Epoch 2, Loss: 1.4325\n",
            "Accuracy of the network on the 5000 validation images: 41.588296760710556 %\n",
            "Epoch 3, Loss: 1.4483\n",
            "Accuracy of the network on the 5000 validation images: 45.45454545454545 %\n",
            "Epoch 4, Loss: 1.3430\n",
            "Accuracy of the network on the 5000 validation images: 50.853361198188786 %\n",
            "Epoch 5, Loss: 1.2888\n",
            "Accuracy of the network on the 5000 validation images: 51.724137931034484 %\n",
            "Epoch 6, Loss: 1.0825\n",
            "Accuracy of the network on the 5000 validation images: 53.95332636711947 %\n",
            "Epoch 7, Loss: 0.9873\n",
            "Accuracy of the network on the 5000 validation images: 53.01288749564612 %\n",
            "Epoch 8, Loss: 0.6660\n",
            "Accuracy of the network on the 5000 validation images: 53.082549634273775 %\n",
            "Epoch 9, Loss: 0.8955\n",
            "Accuracy of the network on the 5000 validation images: 54.057819575060954 %\n",
            "Epoch 10, Loss: 0.5134\n",
            "Accuracy of the network on the 5000 validation images: 52.97805642633229 %\n",
            "Epoch 11, Loss: 0.3935\n",
            "Accuracy of the network on the 5000 validation images: 54.44096133751306 %\n",
            "Epoch 12, Loss: 0.2335\n",
            "Accuracy of the network on the 5000 validation images: 54.754440961337515 %\n",
            "Epoch 13, Loss: 0.4225\n",
            "Accuracy of the network on the 5000 validation images: 55.45106234761407 %\n",
            "Epoch 14, Loss: 0.1432\n",
            "Accuracy of the network on the 5000 validation images: 54.406130268199234 %\n",
            "Epoch 15, Loss: 0.0240\n",
            "Accuracy of the network on the 5000 validation images: 55.93869731800766 %\n",
            "Epoch 16, Loss: 0.1122\n",
            "Accuracy of the network on the 5000 validation images: 56.70498084291188 %\n",
            "Epoch 17, Loss: 0.0686\n",
            "Accuracy of the network on the 5000 validation images: 57.2274468826193 %\n",
            "Epoch 18, Loss: 0.0451\n",
            "Accuracy of the network on the 5000 validation images: 58.37687216997562 %\n",
            "Epoch 19, Loss: 0.0407\n",
            "Accuracy of the network on the 5000 validation images: 57.436433298502266 %\n",
            "Epoch 20, Loss: 0.0027\n",
            "Accuracy of the network on the 5000 validation images: 57.784743991640546 %\n",
            "Epoch 21, Loss: 0.0237\n",
            "Accuracy of the network on the 5000 validation images: 57.6105886450714 %\n",
            "Epoch 22, Loss: 0.0005\n",
            "Accuracy of the network on the 5000 validation images: 57.81957506095437 %\n",
            "Epoch 23, Loss: 0.0030\n",
            "Accuracy of the network on the 5000 validation images: 57.99373040752351 %\n",
            "Epoch 24, Loss: 0.0008\n",
            "Accuracy of the network on the 5000 validation images: 57.57575757575758 %\n",
            "Epoch 25, Loss: 0.0073\n",
            "Accuracy of the network on the 5000 validation images: 57.33194009056078 %\n",
            "Epoch 26, Loss: 0.0495\n",
            "Accuracy of the network on the 5000 validation images: 58.098223615464995 %\n",
            "Epoch 27, Loss: 0.0003\n",
            "Accuracy of the network on the 5000 validation images: 58.02856147683734 %\n",
            "Epoch 28, Loss: 0.0061\n",
            "Accuracy of the network on the 5000 validation images: 57.436433298502266 %\n",
            "Epoch 29, Loss: 0.0098\n",
            "Accuracy of the network on the 5000 validation images: 57.57575757575758 %\n",
            "Epoch 30, Loss: 0.0051\n",
            "Accuracy of the network on the 5000 validation images: 57.68025078369906 %\n",
            "Epoch 31, Loss: 0.0004\n",
            "Accuracy of the network on the 5000 validation images: 57.95889933820968 %\n",
            "Epoch 32, Loss: 0.0002\n",
            "Accuracy of the network on the 5000 validation images: 58.55102751654476 %\n",
            "Epoch 33, Loss: 0.0110\n",
            "Accuracy of the network on the 5000 validation images: 57.8544061302682 %\n",
            "Epoch 34, Loss: 0.0004\n",
            "Accuracy of the network on the 5000 validation images: 57.68025078369906 %\n",
            "Epoch 35, Loss: 0.0038\n",
            "Accuracy of the network on the 5000 validation images: 58.55102751654476 %\n",
            "Epoch 36, Loss: 0.0005\n",
            "Accuracy of the network on the 5000 validation images: 57.68025078369906 %\n",
            "Epoch 37, Loss: 0.0001\n",
            "Accuracy of the network on the 5000 validation images: 57.749912922326715 %\n",
            "Epoch 38, Loss: 0.0060\n",
            "Accuracy of the network on the 5000 validation images: 57.6105886450714 %\n",
            "Epoch 39, Loss: 0.0003\n",
            "Accuracy of the network on the 5000 validation images: 57.71508185301289 %\n",
            "Epoch 40, Loss: 0.0002\n",
            "Accuracy of the network on the 5000 validation images: 57.99373040752351 %\n",
            "Epoch 41, Loss: 0.0006\n",
            "Accuracy of the network on the 5000 validation images: 57.784743991640546 %\n",
            "Epoch 42, Loss: 0.0001\n",
            "Accuracy of the network on the 5000 validation images: 58.202716823406476 %\n",
            "Epoch 43, Loss: 0.0002\n",
            "Accuracy of the network on the 5000 validation images: 57.540926506443746 %\n",
            "Epoch 44, Loss: 0.0003\n",
            "Accuracy of the network on the 5000 validation images: 57.784743991640546 %\n",
            "Epoch 45, Loss: 0.0004\n",
            "Accuracy of the network on the 5000 validation images: 58.063392546151164 %\n",
            "Epoch 46, Loss: 0.0002\n",
            "Accuracy of the network on the 5000 validation images: 57.436433298502266 %\n",
            "Epoch 47, Loss: 0.0001\n",
            "Accuracy of the network on the 5000 validation images: 58.063392546151164 %\n",
            "Epoch 48, Loss: 0.0002\n",
            "Accuracy of the network on the 5000 validation images: 57.47126436781609 %\n",
            "Epoch 49, Loss: 0.0070\n",
            "Accuracy of the network on the 5000 validation images: 58.34204110066179 %\n",
            "Epoch 50, Loss: 0.0003\n",
            "Accuracy of the network on the 5000 validation images: 57.99373040752351 %\n",
            "[0.2939742250087078, 0.4158829676071055, 0.45454545454545453, 0.5085336119818878, 0.5172413793103449, 0.5395332636711947, 0.5301288749564612, 0.5308254963427377, 0.5405781957506095, 0.5297805642633229, 0.5444096133751306, 0.5475444096133751, 0.5545106234761407, 0.5440613026819924, 0.5593869731800766, 0.5670498084291188, 0.5722744688261929, 0.5837687216997561, 0.5743643329850227, 0.5778474399164054, 0.576105886450714, 0.5781957506095438, 0.5799373040752351, 0.5757575757575758, 0.5733194009056078, 0.58098223615465, 0.5802856147683734, 0.5743643329850227, 0.5757575757575758, 0.5768025078369906, 0.5795889933820968, 0.5855102751654476, 0.578544061302682, 0.5768025078369906, 0.5855102751654476, 0.5768025078369906, 0.5774991292232672, 0.576105886450714, 0.5771508185301288, 0.5799373040752351, 0.5778474399164054, 0.5820271682340648, 0.5754092650644375, 0.5778474399164054, 0.5806339254615117, 0.5743643329850227, 0.5806339254615117, 0.5747126436781609, 0.5834204110066179, 0.5799373040752351]\n",
            "[1.817366600036621, 1.4325112104415894, 1.448268175125122, 1.3429588079452515, 1.2887524366378784, 1.082478404045105, 0.9872622489929199, 0.6659968495368958, 0.8954899907112122, 0.5133786201477051, 0.3935321867465973, 0.23353685438632965, 0.4224945902824402, 0.14320747554302216, 0.024044277146458626, 0.11221261322498322, 0.06861086189746857, 0.045069269835948944, 0.04068467766046524, 0.0027097826823592186, 0.02369409240782261, 0.00046178020420484245, 0.0029926577117294073, 0.000753006199374795, 0.007310739252716303, 0.04954054579138756, 0.0002716589078772813, 0.006055742967873812, 0.009830757975578308, 0.005133442115038633, 0.00037000601878389716, 0.00024050252977758646, 0.01097183208912611, 0.000418186275055632, 0.0038040708750486374, 0.0005042366101406515, 0.00013357220450416207, 0.005998593755066395, 0.0003158611070830375, 0.00020177186524961144, 0.0006288671283982694, 0.00012353889178484678, 0.00019043633074034005, 0.00027027723263017833, 0.0003507818910293281, 0.00017842977831605822, 0.00013357259740587324, 0.00019166190759278834, 0.007007270120084286, 0.000318775448249653]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_preds = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        preds = predicted.cpu().numpy()\n",
        "        labels = labels.cpu().numpy()\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(labels)\n",
        "        del images, labels, outputs\n",
        "    print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvB_jT-F89Pc",
        "outputId": "6b7cae03-e4a6-4d4b-fca2-9608ebc643b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 57.31401504597381 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "print(cm)\n",
        "# for x, y in zip(all_labels, all_preds):\n",
        "#   print(x,y)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(cm, cmap=plt.cm.Blues)\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(7)\n",
        "plt.xticks(tick_marks, tick_marks)\n",
        "plt.yticks(tick_marks, tick_marks)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "id": "zEGSlYO-8-gC",
        "outputId": "b312537d-7ba9-40a7-a90a-f81987561f4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 467    6   92   78  120  162   33]\n",
            " [  28   41    7    9    7   16    3]\n",
            " [ 141    4  367   81  135  205   91]\n",
            " [  52    1   55 1438   86   97   45]\n",
            " [ 110    1  113  144  641  203   21]\n",
            " [ 141    3  174  105  238  558   28]\n",
            " [  27    1   78   57   35   31  602]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}